{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Visualization with ghops\n",
    "\n",
    "This notebook demonstrates how to analyze and visualize your repository portfolio using ghops data. Learn to create insightful dashboards, perform time series analysis, and build interactive visualizations.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Loading and Preparing Data](#loading-data)\n",
    "2. [Repository Portfolio Analysis](#portfolio-analysis)\n",
    "3. [Creating Visualizations](#creating-visualizations)\n",
    "4. [Interactive Dashboards](#interactive-dashboards)\n",
    "5. [Network Graph Analysis](#network-analysis)\n",
    "6. [Time Series Analysis](#time-series)\n",
    "7. [Statistical Analysis](#statistical-analysis)\n",
    "8. [Custom Metrics and KPIs](#custom-metrics)\n",
    "9. [Reporting and Export](#reporting)\n",
    "10. [Exercises](#exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import networkx as nx\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create workspace\n",
    "workspace = tempfile.mkdtemp(prefix=\"ghops_analysis_\")\n",
    "print(f\"Workspace: {workspace}\")\n",
    "\n",
    "# Helper functions\n",
    "def run_command(cmd):\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    return result.stdout, result.stderr, result.returncode\n",
    "\n",
    "def parse_jsonl(output):\n",
    "    results = []\n",
    "    for line in output.strip().split('\\n'):\n",
    "        if line:\n",
    "            try:\n",
    "                results.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Preparing Data {#loading-data}\n",
    "\n",
    "First, let's generate and load repository data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample repository data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Repository categories\n",
    "categories = ['web', 'api', 'ml', 'data', 'tool', 'lib', 'docs']\n",
    "languages = ['Python', 'JavaScript', 'Go', 'Rust', 'TypeScript', 'Java']\n",
    "licenses = ['MIT', 'Apache-2.0', 'GPL-3.0', 'BSD-3-Clause', 'Proprietary']\n",
    "\n",
    "# Generate sample repositories\n",
    "num_repos = 50\n",
    "repos_data = []\n",
    "\n",
    "for i in range(num_repos):\n",
    "    category = np.random.choice(categories)\n",
    "    language = np.random.choice(languages)\n",
    "    \n",
    "    repo = {\n",
    "        'name': f'{category}-project-{i:03d}',\n",
    "        'category': category,\n",
    "        'language': language,\n",
    "        'license': np.random.choice(licenses),\n",
    "        'stars': np.random.randint(0, 1000) if np.random.random() > 0.3 else 0,\n",
    "        'forks': np.random.randint(0, 100),\n",
    "        'issues': np.random.randint(0, 50),\n",
    "        'pull_requests': np.random.randint(0, 20),\n",
    "        'commits': np.random.randint(10, 1000),\n",
    "        'contributors': np.random.randint(1, 20),\n",
    "        'lines_of_code': np.random.randint(100, 50000),\n",
    "        'test_coverage': np.random.uniform(0, 100) if np.random.random() > 0.2 else 0,\n",
    "        'last_commit_days': np.random.randint(0, 365),\n",
    "        'created_date': datetime.now() - timedelta(days=np.random.randint(30, 1500)),\n",
    "        'size_mb': np.random.uniform(0.1, 500),\n",
    "        'dependencies': np.random.randint(0, 50),\n",
    "        'is_private': np.random.random() > 0.7,\n",
    "        'has_ci': np.random.random() > 0.3,\n",
    "        'has_docs': np.random.random() > 0.4,\n",
    "        'complexity_score': np.random.uniform(1, 10)\n",
    "    }\n",
    "    \n",
    "    # Calculate health score\n",
    "    health_factors = [\n",
    "        min(repo['test_coverage'] / 100, 1) * 25,\n",
    "        (1 - min(repo['last_commit_days'] / 365, 1)) * 25,\n",
    "        min(repo['contributors'] / 10, 1) * 25,\n",
    "        (1 if repo['has_docs'] else 0) * 15,\n",
    "        (1 if repo['has_ci'] else 0) * 10\n",
    "    ]\n",
    "    repo['health_score'] = sum(health_factors)\n",
    "    \n",
    "    repos_data.append(repo)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(repos_data)\n",
    "df['created_date'] = pd.to_datetime(df['created_date'])\n",
    "\n",
    "print(f\"Loaded {len(df)} repositories\")\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 repositories:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Repository Portfolio Analysis {#portfolio-analysis}\n",
    "\n",
    "Analyze your repository portfolio composition and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio summary statistics\n",
    "print(\"Portfolio Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Repositories: {len(df)}\")\n",
    "print(f\"Private Repositories: {df['is_private'].sum()} ({df['is_private'].mean()*100:.1f}%)\")\n",
    "print(f\"Total Lines of Code: {df['lines_of_code'].sum():,}\")\n",
    "print(f\"Total Contributors: {df['contributors'].sum()}\")\n",
    "print(f\"Average Health Score: {df['health_score'].mean():.1f}/100\")\n",
    "print(f\"\\nLanguage Distribution:\")\n",
    "print(df['language'].value_counts().head())\n",
    "print(f\"\\nCategory Distribution:\")\n",
    "print(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio composition visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Language distribution\n",
    "ax1 = axes[0, 0]\n",
    "df['language'].value_counts().plot(kind='pie', ax=ax1, autopct='%1.1f%%')\n",
    "ax1.set_title('Language Distribution')\n",
    "ax1.set_ylabel('')\n",
    "\n",
    "# Category distribution\n",
    "ax2 = axes[0, 1]\n",
    "df['category'].value_counts().plot(kind='bar', ax=ax2, color='skyblue')\n",
    "ax2.set_title('Repository Categories')\n",
    "ax2.set_xlabel('Category')\n",
    "ax2.set_ylabel('Count')\n",
    "\n",
    "# License distribution\n",
    "ax3 = axes[0, 2]\n",
    "df['license'].value_counts().plot(kind='barh', ax=ax3, color='lightgreen')\n",
    "ax3.set_title('License Types')\n",
    "ax3.set_xlabel('Count')\n",
    "\n",
    "# Health score distribution\n",
    "ax4 = axes[1, 0]\n",
    "ax4.hist(df['health_score'], bins=20, color='coral', edgecolor='black')\n",
    "ax4.set_title('Health Score Distribution')\n",
    "ax4.set_xlabel('Health Score')\n",
    "ax4.set_ylabel('Count')\n",
    "ax4.axvline(df['health_score'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"health_score\"].mean():.1f}')\n",
    "ax4.legend()\n",
    "\n",
    "# Activity heatmap (last commit)\n",
    "ax5 = axes[1, 1]\n",
    "activity_bins = [0, 7, 30, 90, 180, 365]\n",
    "activity_labels = ['< 1 week', '1-4 weeks', '1-3 months', '3-6 months', '> 6 months']\n",
    "df['activity_category'] = pd.cut(df['last_commit_days'], bins=activity_bins, labels=activity_labels)\n",
    "activity_counts = df['activity_category'].value_counts()\n",
    "colors = ['darkgreen', 'green', 'yellow', 'orange', 'red']\n",
    "ax5.bar(range(len(activity_counts)), activity_counts.values, color=colors)\n",
    "ax5.set_xticks(range(len(activity_counts)))\n",
    "ax5.set_xticklabels(activity_counts.index, rotation=45)\n",
    "ax5.set_title('Repository Activity Status')\n",
    "ax5.set_ylabel('Count')\n",
    "\n",
    "# Size distribution\n",
    "ax6 = axes[1, 2]\n",
    "ax6.scatter(df['lines_of_code'], df['size_mb'], alpha=0.6, c=df['health_score'], cmap='viridis')\n",
    "ax6.set_title('Repository Size Analysis')\n",
    "ax6.set_xlabel('Lines of Code')\n",
    "ax6.set_ylabel('Size (MB)')\n",
    "ax6.set_xscale('log')\n",
    "ax6.set_yscale('log')\n",
    "cbar = plt.colorbar(ax6.collections[0], ax=ax6)\n",
    "cbar.set_label('Health Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Visualizations {#creating-visualizations}\n",
    "\n",
    "Create various types of visualizations to understand your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced visualizations with Plotly\n",
    "\n",
    "# 1. Sunburst chart for hierarchical data\n",
    "hierarchy_df = df.groupby(['language', 'category']).size().reset_index(name='count')\n",
    "hierarchy_df['path'] = hierarchy_df['language'] + '/' + hierarchy_df['category']\n",
    "\n",
    "fig_sunburst = px.sunburst(\n",
    "    hierarchy_df,\n",
    "    path=['language', 'category'],\n",
    "    values='count',\n",
    "    title='Repository Hierarchy: Language â†’ Category'\n",
    ")\n",
    "fig_sunburst.show()\n",
    "\n",
    "# 2. Scatter matrix for correlation analysis\n",
    "metrics = ['stars', 'forks', 'contributors', 'health_score', 'test_coverage']\n",
    "fig_scatter = px.scatter_matrix(\n",
    "    df[metrics],\n",
    "    dimensions=metrics,\n",
    "    color=df['health_score'],\n",
    "    title='Repository Metrics Correlation Matrix',\n",
    "    height=800\n",
    ")\n",
    "fig_scatter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Box plots for comparative analysis\n",
    "fig_box = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Health Score by Language', 'Test Coverage by Category',\n",
    "                   'Contributors by Language', 'Complexity by Category')\n",
    ")\n",
    "\n",
    "# Health Score by Language\n",
    "for lang in df['language'].unique():\n",
    "    lang_data = df[df['language'] == lang]['health_score']\n",
    "    fig_box.add_trace(\n",
    "        go.Box(y=lang_data, name=lang, showlegend=False),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Test Coverage by Category\n",
    "for cat in df['category'].unique():\n",
    "    cat_data = df[df['category'] == cat]['test_coverage']\n",
    "    fig_box.add_trace(\n",
    "        go.Box(y=cat_data, name=cat, showlegend=False),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Contributors by Language\n",
    "for lang in df['language'].unique():\n",
    "    lang_data = df[df['language'] == lang]['contributors']\n",
    "    fig_box.add_trace(\n",
    "        go.Box(y=lang_data, name=lang, showlegend=False),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# Complexity by Category  \n",
    "for cat in df['category'].unique():\n",
    "    cat_data = df[df['category'] == cat]['complexity_score']\n",
    "    fig_box.add_trace(\n",
    "        go.Box(y=cat_data, name=cat, showlegend=False),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "fig_box.update_layout(height=800, title_text=\"Comparative Analysis\")\n",
    "fig_box.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Dashboards {#interactive-dashboards}\n",
    "\n",
    "Build interactive dashboards for real-time monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive dashboard\n",
    "from ipywidgets import interact, widgets, VBox, HBox\n",
    "import IPython.display as display\n",
    "\n",
    "def create_dashboard(language='All', category='All', min_health=0):\n",
    "    \"\"\"Create filtered dashboard based on selections\"\"\"\n",
    "    \n",
    "    # Filter data\n",
    "    filtered_df = df.copy()\n",
    "    if language != 'All':\n",
    "        filtered_df = filtered_df[filtered_df['language'] == language]\n",
    "    if category != 'All':\n",
    "        filtered_df = filtered_df[filtered_df['category'] == category]\n",
    "    filtered_df = filtered_df[filtered_df['health_score'] >= min_health]\n",
    "    \n",
    "    # Create dashboard\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=3,\n",
    "        specs=[[{'type': 'indicator'}, {'type': 'indicator'}, {'type': 'indicator'}],\n",
    "               [{'type': 'bar'}, {'type': 'scatter', 'colspan': 2}, None]],\n",
    "        subplot_titles=('Total Repos', 'Avg Health', 'Total Contributors',\n",
    "                       'Top Repos by Stars', 'Health vs Activity')\n",
    "    )\n",
    "    \n",
    "    # KPI Indicators\n",
    "    fig.add_trace(\n",
    "        go.Indicator(\n",
    "            mode=\"number+delta\",\n",
    "            value=len(filtered_df),\n",
    "            delta={'reference': len(df)},\n",
    "            title={'text': 'Repositories'},\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Indicator(\n",
    "            mode=\"gauge+number\",\n",
    "            value=filtered_df['health_score'].mean(),\n",
    "            title={'text': 'Avg Health'},\n",
    "            gauge={'axis': {'range': [0, 100]},\n",
    "                  'bar': {'color': 'darkgreen'},\n",
    "                  'steps': [\n",
    "                      {'range': [0, 50], 'color': 'lightgray'},\n",
    "                      {'range': [50, 80], 'color': 'yellow'}],\n",
    "                  'threshold': {'value': 80, 'thickness': 0.75}}\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Indicator(\n",
    "            mode=\"number\",\n",
    "            value=filtered_df['contributors'].sum(),\n",
    "            title={'text': 'Total Contributors'},\n",
    "        ),\n",
    "        row=1, col=3\n",
    "    )\n",
    "    \n",
    "    # Top repositories by stars\n",
    "    top_repos = filtered_df.nlargest(10, 'stars')[['name', 'stars']]\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=top_repos['stars'], y=top_repos['name'], orientation='h'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Health vs Activity scatter\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=filtered_df['last_commit_days'],\n",
    "            y=filtered_df['health_score'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=filtered_df['contributors'] * 2,\n",
    "                color=filtered_df['test_coverage'],\n",
    "                colorscale='Viridis',\n",
    "                showscale=True,\n",
    "                colorbar=dict(x=1.1)\n",
    "            ),\n",
    "            text=filtered_df['name'],\n",
    "            hovertemplate='%{text}<br>Health: %{y:.1f}<br>Days since commit: %{x}'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Days Since Last Commit\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Health Score\", row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        showlegend=False,\n",
    "        title_text=f\"Repository Dashboard (Filtered: {len(filtered_df)} repos)\"\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nFiltered Statistics:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Repositories: {len(filtered_df)}\")\n",
    "    print(f\"Avg Health Score: {filtered_df['health_score'].mean():.1f}\")\n",
    "    print(f\"Avg Test Coverage: {filtered_df['test_coverage'].mean():.1f}%\")\n",
    "    print(f\"Total Lines of Code: {filtered_df['lines_of_code'].sum():,}\")\n",
    "\n",
    "# Create interactive widgets\n",
    "language_widget = widgets.Dropdown(\n",
    "    options=['All'] + list(df['language'].unique()),\n",
    "    value='All',\n",
    "    description='Language:'\n",
    ")\n",
    "\n",
    "category_widget = widgets.Dropdown(\n",
    "    options=['All'] + list(df['category'].unique()),\n",
    "    value='All',\n",
    "    description='Category:'\n",
    ")\n",
    "\n",
    "health_widget = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=10,\n",
    "    description='Min Health:'\n",
    ")\n",
    "\n",
    "# Create interactive dashboard\n",
    "interact(create_dashboard, \n",
    "         language=language_widget,\n",
    "         category=category_widget,\n",
    "         min_health=health_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Network Graph Analysis {#network-analysis}\n",
    "\n",
    "Visualize relationships between repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create repository network based on shared characteristics\n",
    "import networkx as nx\n",
    "\n",
    "# Create network graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes for repositories\n",
    "for idx, repo in df.iterrows():\n",
    "    G.add_node(repo['name'], \n",
    "              language=repo['language'],\n",
    "              category=repo['category'],\n",
    "              health=repo['health_score'])\n",
    "\n",
    "# Add edges based on similarity\n",
    "threshold = 0.7  # Similarity threshold\n",
    "\n",
    "for i, repo1 in df.iterrows():\n",
    "    for j, repo2 in df.iterrows():\n",
    "        if i < j:  # Avoid duplicates\n",
    "            # Calculate similarity based on multiple factors\n",
    "            similarity = 0\n",
    "            if repo1['language'] == repo2['language']:\n",
    "                similarity += 0.4\n",
    "            if repo1['category'] == repo2['category']:\n",
    "                similarity += 0.3\n",
    "            if abs(repo1['health_score'] - repo2['health_score']) < 20:\n",
    "                similarity += 0.3\n",
    "            \n",
    "            if similarity >= threshold:\n",
    "                G.add_edge(repo1['name'], repo2['name'], weight=similarity)\n",
    "\n",
    "# Calculate network metrics\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness = nx.betweenness_centrality(G)\n",
    "communities = nx.community.greedy_modularity_communities(G)\n",
    "\n",
    "print(f\"Network Statistics:\")\n",
    "print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G.number_of_edges()}\")\n",
    "print(f\"  Communities: {len(communities)}\")\n",
    "print(f\"  Average Degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize network with Plotly\n",
    "pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "\n",
    "# Extract node positions\n",
    "edge_trace = []\n",
    "for edge in G.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_trace.append(\n",
    "        go.Scatter(x=[x0, x1, None], y=[y0, y1, None],\n",
    "                  mode='lines',\n",
    "                  line=dict(width=0.5, color='gray'),\n",
    "                  hoverinfo='none')\n",
    "    )\n",
    "\n",
    "# Node trace\n",
    "node_x = []\n",
    "node_y = []\n",
    "node_text = []\n",
    "node_color = []\n",
    "\n",
    "for node in G.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "    node_text.append(f\"{node}<br>Connections: {G.degree(node)}\")\n",
    "    node_color.append(G.degree(node))\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    text=node_text,\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        colorscale='YlOrRd',\n",
    "        size=10,\n",
    "        color=node_color,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='Connections',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create figure\n",
    "fig_network = go.Figure(data=edge_trace + [node_trace],\n",
    "                       layout=go.Layout(\n",
    "                           title='Repository Network Graph',\n",
    "                           showlegend=False,\n",
    "                           hovermode='closest',\n",
    "                           margin=dict(b=0,l=0,r=0,t=40),\n",
    "                           xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                           yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                           height=600\n",
    "                       ))\n",
    "fig_network.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time Series Analysis {#time-series}\n",
    "\n",
    "Analyze repository trends over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate time series data\n",
    "dates = pd.date_range(start='2023-01-01', end='2024-12-31', freq='D')\n",
    "time_series_data = []\n",
    "\n",
    "for date in dates:\n",
    "    # Simulate daily metrics\n",
    "    daily_commits = np.random.poisson(5)\n",
    "    daily_prs = np.random.poisson(2)\n",
    "    daily_issues = np.random.poisson(3)\n",
    "    active_repos = np.random.randint(20, 40)\n",
    "    \n",
    "    # Add weekly pattern\n",
    "    if date.weekday() >= 5:  # Weekend\n",
    "        daily_commits *= 0.3\n",
    "        daily_prs *= 0.2\n",
    "    \n",
    "    time_series_data.append({\n",
    "        'date': date,\n",
    "        'commits': int(daily_commits),\n",
    "        'pull_requests': int(daily_prs),\n",
    "        'issues': int(daily_issues),\n",
    "        'active_repos': active_repos\n",
    "    })\n",
    "\n",
    "ts_df = pd.DataFrame(time_series_data)\n",
    "ts_df['date'] = pd.to_datetime(ts_df['date'])\n",
    "ts_df.set_index('date', inplace=True)\n",
    "\n",
    "# Calculate rolling averages\n",
    "ts_df['commits_7d_avg'] = ts_df['commits'].rolling(window=7).mean()\n",
    "ts_df['commits_30d_avg'] = ts_df['commits'].rolling(window=30).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series visualizations\n",
    "fig_ts = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    subplot_titles=('Daily Commits with Moving Averages',\n",
    "                   'Weekly Activity Pattern',\n",
    "                   'Monthly Trends'),\n",
    "    specs=[[{'secondary_y': False}],\n",
    "           [{'secondary_y': False}],\n",
    "           [{'secondary_y': True}]]\n",
    ")\n",
    "\n",
    "# Daily commits with moving averages\n",
    "fig_ts.add_trace(\n",
    "    go.Scatter(x=ts_df.index, y=ts_df['commits'],\n",
    "              name='Daily Commits', line=dict(color='lightblue', width=1)),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig_ts.add_trace(\n",
    "    go.Scatter(x=ts_df.index, y=ts_df['commits_7d_avg'],\n",
    "              name='7-Day Avg', line=dict(color='blue', width=2)),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig_ts.add_trace(\n",
    "    go.Scatter(x=ts_df.index, y=ts_df['commits_30d_avg'],\n",
    "              name='30-Day Avg', line=dict(color='darkblue', width=2)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Weekly activity pattern\n",
    "weekly_pattern = ts_df.groupby(ts_df.index.dayofweek).mean()\n",
    "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "fig_ts.add_trace(\n",
    "    go.Bar(x=days, y=weekly_pattern['commits'],\n",
    "          name='Avg Commits', marker_color='green'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Monthly trends\n",
    "monthly_data = ts_df.resample('M').sum()\n",
    "fig_ts.add_trace(\n",
    "    go.Bar(x=monthly_data.index, y=monthly_data['commits'],\n",
    "          name='Monthly Commits', marker_color='orange'),\n",
    "    row=3, col=1\n",
    ")\n",
    "fig_ts.add_trace(\n",
    "    go.Scatter(x=monthly_data.index, y=monthly_data['active_repos'].cumsum(),\n",
    "              name='Cumulative Active', line=dict(color='red', width=2)),\n",
    "    row=3, col=1, secondary_y=True\n",
    ")\n",
    "\n",
    "fig_ts.update_xaxes(title_text=\"Date\", row=3, col=1)\n",
    "fig_ts.update_yaxes(title_text=\"Commits\", row=1, col=1)\n",
    "fig_ts.update_yaxes(title_text=\"Avg Commits\", row=2, col=1)\n",
    "fig_ts.update_yaxes(title_text=\"Monthly Commits\", row=3, col=1)\n",
    "fig_ts.update_yaxes(title_text=\"Cumulative Active\", row=3, col=1, secondary_y=True)\n",
    "\n",
    "fig_ts.update_layout(height=900, title_text=\"Repository Activity Time Series Analysis\")\n",
    "fig_ts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Statistical Analysis {#statistical-analysis}\n",
    "\n",
    "Perform statistical analysis to find insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "correlation_matrix = df[['stars', 'forks', 'issues', 'contributors', \n",
    "                         'health_score', 'test_coverage', 'complexity_score']].corr()\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1)\n",
    "plt.title('Repository Metrics Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(df[['health_score', 'test_coverage', 'contributors', 'complexity_score']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis testing\n",
    "from scipy import stats\n",
    "\n",
    "# Test: Do repositories with CI/CD have better health scores?\n",
    "ci_repos = df[df['has_ci'] == True]['health_score']\n",
    "no_ci_repos = df[df['has_ci'] == False]['health_score']\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(ci_repos, no_ci_repos)\n",
    "\n",
    "print(\"Hypothesis Test: CI/CD Impact on Health Score\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean health score with CI/CD: {ci_repos.mean():.2f}\")\n",
    "print(f\"Mean health score without CI/CD: {no_ci_repos.mean():.2f}\")\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Result: Significant difference (p < 0.05)\")\n",
    "else:\n",
    "    print(\"Result: No significant difference\")\n",
    "\n",
    "# ANOVA: Health score by language\n",
    "language_groups = [df[df['language'] == lang]['health_score'].values \n",
    "                  for lang in df['language'].unique()]\n",
    "f_stat, p_value_anova = stats.f_oneway(*language_groups)\n",
    "\n",
    "print(\"\\nANOVA: Health Score by Programming Language\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value_anova:.4f}\")\n",
    "if p_value_anova < 0.05:\n",
    "    print(\"Result: Significant difference between languages\")\n",
    "else:\n",
    "    print(\"Result: No significant difference between languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Custom Metrics and KPIs {#custom-metrics}\n",
    "\n",
    "Define and track custom metrics for your portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom KPIs\n",
    "class PortfolioKPIs:\n",
    "    \"\"\"Calculate custom KPIs for repository portfolio\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def technical_debt_score(row):\n",
    "        \"\"\"Calculate technical debt based on multiple factors\"\"\"\n",
    "        score = 0\n",
    "        \n",
    "        # Factor in test coverage\n",
    "        if row['test_coverage'] < 30:\n",
    "            score += 30\n",
    "        elif row['test_coverage'] < 60:\n",
    "            score += 15\n",
    "        \n",
    "        # Factor in complexity\n",
    "        score += row['complexity_score'] * 3\n",
    "        \n",
    "        # Factor in age without updates\n",
    "        if row['last_commit_days'] > 180:\n",
    "            score += 20\n",
    "        elif row['last_commit_days'] > 90:\n",
    "            score += 10\n",
    "        \n",
    "        # Factor in documentation\n",
    "        if not row['has_docs']:\n",
    "            score += 15\n",
    "        \n",
    "        return min(score, 100)  # Cap at 100\n",
    "    \n",
    "    @staticmethod\n",
    "    def maintenance_priority(row):\n",
    "        \"\"\"Calculate maintenance priority\"\"\"\n",
    "        priority = 0\n",
    "        \n",
    "        # High activity repos need more maintenance\n",
    "        if row['contributors'] > 10:\n",
    "            priority += 30\n",
    "        elif row['contributors'] > 5:\n",
    "            priority += 20\n",
    "        \n",
    "        # Critical issues\n",
    "        if row['issues'] > 20:\n",
    "            priority += 25\n",
    "        \n",
    "        # Low health score\n",
    "        if row['health_score'] < 50:\n",
    "            priority += 25\n",
    "        \n",
    "        # No CI/CD\n",
    "        if not row['has_ci']:\n",
    "            priority += 20\n",
    "        \n",
    "        return priority\n",
    "    \n",
    "    @staticmethod\n",
    "    def innovation_index(row):\n",
    "        \"\"\"Calculate innovation index based on activity and growth\"\"\"\n",
    "        index = 0\n",
    "        \n",
    "        # Recent activity\n",
    "        if row['last_commit_days'] < 7:\n",
    "            index += 40\n",
    "        elif row['last_commit_days'] < 30:\n",
    "            index += 25\n",
    "        \n",
    "        # Contributor growth\n",
    "        index += min(row['contributors'] * 2, 30)\n",
    "        \n",
    "        # Complexity (innovative projects might be more complex)\n",
    "        if row['complexity_score'] > 7:\n",
    "            index += 15\n",
    "        \n",
    "        # Size growth\n",
    "        if row['lines_of_code'] > 10000:\n",
    "            index += 15\n",
    "        \n",
    "        return min(index, 100)\n",
    "\n",
    "# Calculate custom KPIs\n",
    "df['technical_debt'] = df.apply(PortfolioKPIs.technical_debt_score, axis=1)\n",
    "df['maintenance_priority'] = df.apply(PortfolioKPIs.maintenance_priority, axis=1)\n",
    "df['innovation_index'] = df.apply(PortfolioKPIs.innovation_index, axis=1)\n",
    "\n",
    "# Display top repositories by each KPI\n",
    "print(\"Custom KPI Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nTop 5 Repositories by Technical Debt:\")\n",
    "print(df.nlargest(5, 'technical_debt')[['name', 'technical_debt', 'test_coverage', 'complexity_score']])\n",
    "\n",
    "print(\"\\nTop 5 Repositories by Maintenance Priority:\")\n",
    "print(df.nlargest(5, 'maintenance_priority')[['name', 'maintenance_priority', 'issues', 'health_score']])\n",
    "\n",
    "print(\"\\nTop 5 Most Innovative Repositories:\")\n",
    "print(df.nlargest(5, 'innovation_index')[['name', 'innovation_index', 'last_commit_days', 'contributors']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPI Dashboard\n",
    "fig_kpi = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Technical Debt Distribution',\n",
    "                   'Maintenance Priority Matrix',\n",
    "                   'Innovation vs Health',\n",
    "                   'Portfolio Risk Assessment'),\n",
    "    specs=[[{'type': 'histogram'}, {'type': 'scatter'}],\n",
    "           [{'type': 'scatter'}, {'type': 'pie'}]]\n",
    ")\n",
    "\n",
    "# Technical debt distribution\n",
    "fig_kpi.add_trace(\n",
    "    go.Histogram(x=df['technical_debt'], nbinsx=20,\n",
    "                marker_color='red', name='Tech Debt'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Maintenance priority matrix\n",
    "fig_kpi.add_trace(\n",
    "    go.Scatter(x=df['maintenance_priority'], y=df['health_score'],\n",
    "              mode='markers',\n",
    "              marker=dict(size=df['issues'], color=df['technical_debt'],\n",
    "                         colorscale='RdYlGn_r', showscale=True),\n",
    "              text=df['name'],\n",
    "              hovertemplate='%{text}<br>Priority: %{x}<br>Health: %{y:.1f}'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Innovation vs Health\n",
    "fig_kpi.add_trace(\n",
    "    go.Scatter(x=df['innovation_index'], y=df['health_score'],\n",
    "              mode='markers',\n",
    "              marker=dict(size=10, color=df['category'].astype('category').cat.codes),\n",
    "              text=df['name']),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Risk assessment pie\n",
    "risk_categories = pd.cut(df['technical_debt'], \n",
    "                         bins=[0, 30, 60, 100],\n",
    "                         labels=['Low Risk', 'Medium Risk', 'High Risk'])\n",
    "risk_counts = risk_categories.value_counts()\n",
    "\n",
    "fig_kpi.add_trace(\n",
    "    go.Pie(labels=risk_counts.index, values=risk_counts.values,\n",
    "          marker=dict(colors=['green', 'yellow', 'red'])),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update axes labels\n",
    "fig_kpi.update_xaxes(title_text=\"Technical Debt Score\", row=1, col=1)\n",
    "fig_kpi.update_xaxes(title_text=\"Maintenance Priority\", row=1, col=2)\n",
    "fig_kpi.update_xaxes(title_text=\"Innovation Index\", row=2, col=1)\n",
    "fig_kpi.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "fig_kpi.update_yaxes(title_text=\"Health Score\", row=1, col=2)\n",
    "fig_kpi.update_yaxes(title_text=\"Health Score\", row=2, col=1)\n",
    "\n",
    "fig_kpi.update_layout(height=800, title_text=\"Custom KPI Dashboard\", showlegend=False)\n",
    "fig_kpi.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reporting and Export {#reporting}\n",
    "\n",
    "Generate reports and export data for stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate executive report\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_executive_report(df, output_file='executive_report.html'):\n",
    "    \"\"\"Generate comprehensive executive report\"\"\"\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    total_repos = len(df)\n",
    "    avg_health = df['health_score'].mean()\n",
    "    total_contributors = df['contributors'].sum()\n",
    "    total_loc = df['lines_of_code'].sum()\n",
    "    \n",
    "    # High risk repos\n",
    "    high_risk = df[df['technical_debt'] > 60]\n",
    "    \n",
    "    # Active repos\n",
    "    active_repos = df[df['last_commit_days'] < 30]\n",
    "    \n",
    "    # Create HTML report\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Repository Portfolio Executive Report</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
    "            h1 {{ color: #333; }}\n",
    "            h2 {{ color: #666; border-bottom: 2px solid #ddd; padding-bottom: 10px; }}\n",
    "            .metric {{ display: inline-block; margin: 20px; padding: 20px; \n",
    "                      background: #f0f0f0; border-radius: 10px; }}\n",
    "            .metric-value {{ font-size: 36px; font-weight: bold; color: #2196F3; }}\n",
    "            .metric-label {{ font-size: 14px; color: #666; margin-top: 5px; }}\n",
    "            table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}\n",
    "            th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}\n",
    "            th {{ background-color: #2196F3; color: white; }}\n",
    "            .warning {{ background-color: #fff3cd; padding: 10px; border-radius: 5px; }}\n",
    "            .success {{ background-color: #d4edda; padding: 10px; border-radius: 5px; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Repository Portfolio Executive Report</h1>\n",
    "        <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "        \n",
    "        <h2>Key Metrics</h2>\n",
    "        <div>\n",
    "            <div class=\"metric\">\n",
    "                <div class=\"metric-value\">{total_repos}</div>\n",
    "                <div class=\"metric-label\">Total Repositories</div>\n",
    "            </div>\n",
    "            <div class=\"metric\">\n",
    "                <div class=\"metric-value\">{avg_health:.1f}</div>\n",
    "                <div class=\"metric-label\">Avg Health Score</div>\n",
    "            </div>\n",
    "            <div class=\"metric\">\n",
    "                <div class=\"metric-value\">{total_contributors}</div>\n",
    "                <div class=\"metric-label\">Total Contributors</div>\n",
    "            </div>\n",
    "            <div class=\"metric\">\n",
    "                <div class=\"metric-value\">{total_loc:,}</div>\n",
    "                <div class=\"metric-label\">Lines of Code</div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <h2>Portfolio Composition</h2>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <th>Language</th>\n",
    "                <th>Count</th>\n",
    "                <th>Percentage</th>\n",
    "            </tr>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add language distribution\n",
    "    for lang, count in df['language'].value_counts().items():\n",
    "        percentage = (count / total_repos) * 100\n",
    "        html_content += f\"\"\"\n",
    "            <tr>\n",
    "                <td>{lang}</td>\n",
    "                <td>{count}</td>\n",
    "                <td>{percentage:.1f}%</td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_content += f\"\"\"\n",
    "        </table>\n",
    "        \n",
    "        <h2>Risk Assessment</h2>\n",
    "        <div class=\"warning\">\n",
    "            <strong>High Risk Repositories:</strong> {len(high_risk)} repositories have technical debt > 60\n",
    "        </div>\n",
    "        \n",
    "        <h2>Activity Status</h2>\n",
    "        <div class=\"success\">\n",
    "            <strong>Active Repositories:</strong> {len(active_repos)} repositories updated in last 30 days\n",
    "        </div>\n",
    "        \n",
    "        <h2>Top Performers</h2>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <th>Repository</th>\n",
    "                <th>Health Score</th>\n",
    "                <th>Stars</th>\n",
    "                <th>Contributors</th>\n",
    "            </tr>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add top performers\n",
    "    top_repos = df.nlargest(5, 'health_score')[['name', 'health_score', 'stars', 'contributors']]\n",
    "    for _, repo in top_repos.iterrows():\n",
    "        html_content += f\"\"\"\n",
    "            <tr>\n",
    "                <td>{repo['name']}</td>\n",
    "                <td>{repo['health_score']:.1f}</td>\n",
    "                <td>{repo['stars']}</td>\n",
    "                <td>{repo['contributors']}</td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "        </table>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save report\n",
    "    report_path = Path(workspace) / output_file\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"Executive report generated: {report_path}\")\n",
    "    return report_path\n",
    "\n",
    "# Generate report\n",
    "report_file = generate_executive_report(df)\n",
    "\n",
    "# Export data to different formats\n",
    "print(\"\\nExporting data...\")\n",
    "\n",
    "# CSV export\n",
    "csv_file = Path(workspace) / 'repository_data.csv'\n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"  CSV: {csv_file}\")\n",
    "\n",
    "# JSON export\n",
    "json_file = Path(workspace) / 'repository_data.json'\n",
    "df.to_json(json_file, orient='records', indent=2, default_handler=str)\n",
    "print(f\"  JSON: {json_file}\")\n",
    "\n",
    "# Excel export with multiple sheets\n",
    "excel_file = Path(workspace) / 'repository_analysis.xlsx'\n",
    "with pd.ExcelWriter(excel_file) as writer:\n",
    "    df.to_excel(writer, sheet_name='All Repositories', index=False)\n",
    "    df.nlargest(10, 'health_score').to_excel(writer, sheet_name='Top Performers', index=False)\n",
    "    df.nlargest(10, 'technical_debt').to_excel(writer, sheet_name='High Risk', index=False)\n",
    "    df.groupby('language').agg({\n",
    "        'name': 'count',\n",
    "        'health_score': 'mean',\n",
    "        'test_coverage': 'mean'\n",
    "    }).to_excel(writer, sheet_name='Language Summary')\n",
    "print(f\"  Excel: {excel_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exercises {#exercises}\n",
    "\n",
    "Practice data analysis and visualization skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Custom Visualization\n",
    "Create a custom visualization showing the relationship between three variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a 3D scatter plot showing:\n",
    "# - X axis: Test coverage\n",
    "# - Y axis: Number of contributors\n",
    "# - Z axis: Health score\n",
    "# - Color: Language\n",
    "# - Size: Lines of code\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Predictive Analysis\n",
    "Build a model to predict repository health score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use machine learning to predict health score\n",
    "# 1. Select features\n",
    "# 2. Split data into training and testing\n",
    "# 3. Train a model (e.g., Random Forest)\n",
    "# 4. Evaluate performance\n",
    "# 5. Identify most important features\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Custom Dashboard\n",
    "Create an interactive dashboard for a specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a dashboard for:\n",
    "# - Security monitoring\n",
    "# - Performance tracking\n",
    "# - Team productivity\n",
    "# Choose one and implement\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up workspace\n",
    "import shutil\n",
    "if 'workspace' in locals() and os.path.exists(workspace):\n",
    "    # List generated files\n",
    "    print(\"Generated files:\")\n",
    "    for file in Path(workspace).glob('*'):\n",
    "        print(f\"  - {file.name}\")\n",
    "    \n",
    "    # Clean up\n",
    "    shutil.rmtree(workspace)\n",
    "    print(f\"\\nCleaned up workspace: {workspace}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "- Loading and preparing repository data for analysis\n",
    "- Comprehensive portfolio analysis techniques\n",
    "- Creating various types of visualizations\n",
    "- Building interactive dashboards\n",
    "- Network graph analysis for repository relationships\n",
    "- Time series analysis for trends\n",
    "- Statistical analysis and hypothesis testing\n",
    "- Defining custom KPIs and metrics\n",
    "- Generating reports and exporting data\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Data-Driven Decisions**: Use analytics to make informed decisions about your portfolio\n",
    "2. **Visual Insights**: Visualizations reveal patterns not visible in raw data\n",
    "3. **Interactive Exploration**: Dashboards enable real-time monitoring and exploration\n",
    "4. **Custom Metrics**: Define KPIs that matter for your specific needs\n",
    "5. **Statistical Rigor**: Use statistical methods to validate hypotheses\n",
    "6. **Automated Reporting**: Generate consistent reports for stakeholders\n",
    "7. **Predictive Analytics**: Use historical data to predict future trends\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Apply these techniques to your actual repository data\n",
    "- Build custom dashboards for your team\n",
    "- Integrate analytics into your CI/CD pipeline\n",
    "- Share insights with stakeholders\n",
    "- Contribute visualizations to the ghops community\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Plotly Documentation](https://plotly.com/python/)\n",
    "- [Pandas Documentation](https://pandas.pydata.org/)\n",
    "- [Seaborn Gallery](https://seaborn.pydata.org/examples/)\n",
    "- [NetworkX Documentation](https://networkx.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}